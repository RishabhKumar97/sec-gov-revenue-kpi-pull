{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f4c9a0b-c631-4635-9d06-f0937df942bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_cik_lookup_df():\n",
    "    # Get CIK lookup table through company tickers endpoint\n",
    "    cik_map = requests.get(\n",
    "        \"https://www.sec.gov/files/company_tickers.json\", headers=header\n",
    "    )\n",
    "    # print(cik_map.status_code)\n",
    "    cik_map_df = spark.createDataFrame(\n",
    "        cik_map.json().values(),\n",
    "        schema=StructType(\n",
    "            [\n",
    "                StructField(\"cik_str\", StringType(), True),\n",
    "                StructField(\"ticker\", StringType(), True),\n",
    "                StructField(\"title\", StringType(), True),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    # padding to get 10 digit cik\n",
    "    cik_map_df = cik_map_df.withColumn(\"cik_str\", F.lpad(F.col(\"cik_str\"), 10, \"0\"))\n",
    "    return cik_map_df\n",
    "\n",
    "\n",
    "def get_company_facts(cik):\n",
    "    # company facts endpoint\n",
    "    URL = f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    comp_facts = requests.get(URL, headers=header)\n",
    "    time.sleep(1)\n",
    "    comp_facts_dict = json.loads(comp_facts.text)\n",
    "    return comp_facts_dict\n",
    "\n",
    "\n",
    "def create_stmnts_combined_df(comp_facts_dict, history_years=3):\n",
    "    # stmnts_to_scan= [stmnt for stmnt in comp_facts_dict['facts']['us-gaap'].keys() if re.search(\"revenue\", stmnt.lower())]\n",
    "    if \"us-gaap\" not in comp_facts_dict[\"facts\"].keys():\n",
    "        return None\n",
    "    else:\n",
    "        stmnts_to_scan = [\n",
    "            \"RevenueFromContractWithCustomerExcludingAssessedTax\",\n",
    "            \"RevenueFromContractWithCustomerIncludingAssessedTax\",\n",
    "            # 'RevenueFromContractsWithCustomers',\n",
    "            \"Revenues\",\n",
    "        ]\n",
    "        stmnts_combined_df_op = spark.createDataFrame(\n",
    "            [],\n",
    "            schema=StructType(\n",
    "                [\n",
    "                    StructField(\"end\", StringType(), True),\n",
    "                    StructField(\"fp\", StringType(), True),\n",
    "                    StructField(\"start\", StringType(), True),\n",
    "                    StructField(\"filed\", StringType(), True),\n",
    "                    StructField(\"time_period_months\", FloatType(), True),\n",
    "                    StructField(\"val\", LongType(), True),\n",
    "                    StructField(\"orig_stmnt\", StringType(), True),\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        for stmnt in stmnts_to_scan:\n",
    "            try:\n",
    "                stmnt_df = spark.createDataFrame(\n",
    "                    comp_facts_dict[\"facts\"][\"us-gaap\"][stmnt][\"units\"][\"USD\"]\n",
    "                )\n",
    "                # check must have columns -- if any statements lacks these skip it\n",
    "                if not (\n",
    "                    {\"start\", \"end\", \"fp\", \"val\", \"filed\"}.issubset(\n",
    "                        set(stmnt_df.columns)\n",
    "                    )\n",
    "                ):\n",
    "                    continue\n",
    "                # basic transformations and filtering\n",
    "                else:\n",
    "                    stmnt_df = (\n",
    "                        stmnt_df.withColumn(\"start\", F.col(\"start\").cast(DateType()))\n",
    "                        .withColumn(\"end\", F.col(\"end\").cast(DateType()))\n",
    "                        .withColumn(\"filed\", F.col(\"filed\").cast(DateType()))\n",
    "                        .withColumn(\"val\", F.col(\"val\").cast(LongType()))\n",
    "                        .withColumn(\n",
    "                            \"time_period_months\",\n",
    "                            F.round(F.months_between(F.col(\"end\"), F.col(\"start\")), 2),\n",
    "                        )\n",
    "                        .withColumn(\"orig_stmnt\", F.lit(stmnt))\n",
    "                    )\n",
    "                    stmnt_df = (\n",
    "                        stmnt_df\n",
    "                        # filtering out records that are not within the last history_years --IMPORTANT\n",
    "                        .filter(\n",
    "                            f\" start > date_sub(current_date(), {history_years*366}) \"\n",
    "                        )\n",
    "                        # filter out rows that are not quarterly/yearly\n",
    "                        .filter(\n",
    "                            \"  (time_period_months between 2.7 and 4) or (time_period_months between 11 and 13) \"\n",
    "                        )\n",
    "                    )\n",
    "                    stmnts_combined_df_op = stmnts_combined_df_op.unionByName(\n",
    "                        stmnt_df.select(\n",
    "                            \"start\",\n",
    "                            \"end\",\n",
    "                            \"fp\",\n",
    "                            \"time_period_months\",\n",
    "                            \"val\",\n",
    "                            \"filed\",\n",
    "                            \"orig_stmnt\",\n",
    "                        )\n",
    "                    )\n",
    "            except KeyError as ke:\n",
    "                continue\n",
    "    return stmnts_combined_df_op.select(\n",
    "        \"start\", \"end\", \"fp\", \"time_period_months\", \"val\", \"filed\", \"orig_stmnt\"\n",
    "    )\n",
    "\n",
    "\n",
    "def remove_inconsistencies(stmnts_combined_df):\n",
    "    stmnts_combined_df_cleansed = (\n",
    "        stmnts_combined_df.withColumn(\n",
    "            \"max_rev\", F.max(\"val\").over(Window.partitionBy(\"start\", \"end\", \"fp\"))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"rank_rev\",\n",
    "            F.row_number().over(\n",
    "                Window.partitionBy(\"start\", \"end\", \"fp\", \"max_rev\").orderBy(\n",
    "                    F.desc(\"val\")\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        .filter(F.col(\"rank_rev\") == 1)\n",
    "        .drop(\"max_rev\", \"rank_rev\")\n",
    "        # Filtering out ambigous cases\n",
    "        .filter(\n",
    "            r\"\"\" fp is not null and not(time_period_months < 11 and fp == \"FY\") and not(time_period_months > 11 and fp rlike \"^Q\\\\d{1}$\") \"\"\"\n",
    "        )\n",
    "        .groupBy(\"start\", \"end\", \"time_period_months\", \"fp\")\n",
    "        .agg(\n",
    "            F.count(F.lit(1)).alias(\"count\"),\n",
    "            F.max(\"val\").alias(\"val\"),\n",
    "            F.collect_list(F.col(\"filed\")).alias(\"list_filed\"),\n",
    "        )\n",
    "        # filtering out rows with less count when start and end are same but fp is different\n",
    "        .withColumn(\n",
    "            \"rn\",\n",
    "            F.rank().over(Window.partitionBy(\"start\", \"end\").orderBy(F.desc(\"count\"))),\n",
    "        )\n",
    "        .filter(F.col(\"rn\") == 1)\n",
    "        # filtering out rows with less count when fp is same and the respective start and end dates are very close in terms of days(inconsistent data)\n",
    "        .withColumn(\"start_month\", F.trunc(F.col(\"start\"), \"month\"))\n",
    "        .withColumn(\"end_month\", F.trunc(F.col(\"end\"), \"month\"))\n",
    "        .withColumn(\n",
    "            \"rnk_m\",\n",
    "            F.rank().over(\n",
    "                Window.partitionBy(\"start_month\", \"end_month\", \"fp\").orderBy(\n",
    "                    F.col(\"count\").desc()\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        .filter(F.col(\"rnk_m\") == 1)\n",
    "        .withColumn(\"week_end\", F.date_trunc(\"week\", F.col(\"end\")))\n",
    "        .withColumn(\"week_start\", F.date_trunc(\"week\", F.col(\"start\")))\n",
    "        .withColumn(\n",
    "            \"rnk_w\",\n",
    "            F.rank().over(\n",
    "                Window.partitionBy(\"week_end\", \"week_start\", \"fp\").orderBy(\n",
    "                    F.col(\"count\").desc()\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        .filter(F.col(\"rnk_w\") == 1)\n",
    "        .withColumn(\"filed\", F.explode(\"list_filed\"))\n",
    "        .drop(\n",
    "            \"rn\",\n",
    "            \"rnk_m\",\n",
    "            \"rnk_w\",\n",
    "            \"week_end\",\n",
    "            \"week_start\",\n",
    "            \"start_month\",\n",
    "            \"end_month\",\n",
    "            \"count\",\n",
    "            \"list_filed\",\n",
    "        )\n",
    "    )\n",
    "    return stmnts_combined_df_cleansed\n",
    "\n",
    "\n",
    "def save_latest_q1_q3(stmnts_combined_df_cleansed):\n",
    "    # save the latest q1-q3 for union later\n",
    "    max_end_fy = (\n",
    "        stmnts_combined_df_cleansed.filter(\" fp == 'FY' \")\n",
    "        .select(F.max(\"end\"))\n",
    "        .first()[0]\n",
    "    )\n",
    "    latest_q1_q3 = stmnts_combined_df_cleansed.filter(F.col(\"end\") > max_end_fy)\n",
    "    return latest_q1_q3\n",
    "\n",
    "\n",
    "def assign_relation_between_q_and_fy(stmnts_combined_df_cleansed):\n",
    "    fy_rows = stmnts_combined_df_cleansed.filter(\" fp == 'FY' \").selectExpr(\n",
    "        \"start as fy_start\", \"end as fy_end\"\n",
    "    )\n",
    "\n",
    "    stmnts_combined_df_with_rel = (\n",
    "        stmnts_combined_df_cleansed.crossJoin(fy_rows)\n",
    "        .filter(\" start >= fy_start and end <= fy_end\")\n",
    "        .withColumn(\n",
    "            \"q1_q3_fy_rel\", F.concat_ws(\" \", F.col(\"fy_start\"), F.col(\"fy_end\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return stmnts_combined_df_with_rel\n",
    "\n",
    "\n",
    "def get_q4_rows(stmnts_combined_df_with_rel):\n",
    "    q4_rows_df = (\n",
    "        stmnts_combined_df_with_rel.withColumn(\n",
    "            \"q1_q3_fy_rev\", F.sum(\"val\").over(Window.partitionBy(\"q1_q3_fy_rel\"))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"q1_q3_rev\",\n",
    "            F.when(F.col(\"fp\") == \"FY\", F.col(\"q1_q3_fy_rev\") - F.col(\"val\")).otherwise(\n",
    "                None\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"q4_rev\",\n",
    "            F.when(F.col(\"fp\") == \"FY\", F.col(\"val\") - F.col(\"q1_q3_rev\")).otherwise(\n",
    "                None\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\"q4_rev\", F.max(\"q4_rev\").over(Window.partitionBy(\"q1_q3_fy_rel\")))\n",
    "        .withColumn(\n",
    "            \"rnk_q1_q3_fy_rel\",\n",
    "            F.rank().over(\n",
    "                Window.partitionBy(\"q1_q3_fy_rel\").orderBy(F.col(\"end\").desc())\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"q4_start\",\n",
    "            F.when(\n",
    "                F.col(\"rnk_q1_q3_fy_rel\") == 2, F.date_add(F.col(\"end\"), 1)\n",
    "            ).otherwise(None),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"q4_end\",\n",
    "            F.when(F.col(\"rnk_q1_q3_fy_rel\") == 1, F.col(\"end\")).otherwise(None),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"q4_filed\",\n",
    "            F.when(F.col(\"rnk_q1_q3_fy_rel\") == 1, F.col(\"filed\")).otherwise(None),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"running_max_q4_start\",\n",
    "            F.max(F.col(\"q4_start\")).over(\n",
    "                Window.rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"running_max_q4_end\",\n",
    "            F.max(F.col(\"q4_end\")).over(\n",
    "                Window.rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"running_max_q4_filed\",\n",
    "            F.max(F.col(\"q4_filed\")).over(\n",
    "                Window.rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"time_period_months_q4\",\n",
    "            F.round(\n",
    "                F.months_between(\n",
    "                    F.col(\"running_max_q4_end\"), F.col(\"running_max_q4_start\")\n",
    "                ),\n",
    "                2,\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"time_period_months_q4\",\n",
    "            F.round(\n",
    "                F.months_between(\n",
    "                    F.col(\"running_max_q4_end\"), F.col(\"running_max_q4_start\")\n",
    "                ),\n",
    "                2,\n",
    "            ),\n",
    "        )\n",
    "        .filter(\" time_period_months_q4 between 2.5 and 4 \")\n",
    "        .withColumn(\"fp\", F.lit(\"Q4\"))\n",
    "        .selectExpr(\n",
    "            \"running_max_q4_start as start\",\n",
    "            \"running_max_q4_end as end\",\n",
    "            \"fp\",\n",
    "            \"q4_rev as val\",\n",
    "            \"running_max_q4_filed as filed\",\n",
    "        )\n",
    "        .distinct()\n",
    "    )\n",
    "    return q4_rows_df\n",
    "\n",
    "\n",
    "def get_fy_all_q_union_df(stmnts_combined_df_with_rel, latest_q1_q3, q4_rows_df):\n",
    "    return (\n",
    "        stmnts_combined_df_with_rel.select(\"start\", \"end\", \"fp\", \"val\", \"filed\")\n",
    "        .unionByName(q4_rows_df)\n",
    "        .unionByName(latest_q1_q3.select(\"start\", \"end\", \"fp\", \"val\", \"filed\"))\n",
    "    )\n",
    "\n",
    "\n",
    "def period_corrected(fy_all_q_union_df):\n",
    "    fy_all_q_union_df_fy_rows = fy_all_q_union_df.filter(\n",
    "        F.col(\"fp\") == \"FY\"\n",
    "    ).selectExpr([\"start as fy_start\", \"end as fy_end\"])\n",
    "    fy_all_q_union_latest_q_rows = save_latest_q1_q3(fy_all_q_union_df)\n",
    "    upto_latest_fy_pc_df = (\n",
    "        fy_all_q_union_df.crossJoin(fy_all_q_union_df_fy_rows)\n",
    "        .filter(\" start >= fy_start and end <= fy_end\")\n",
    "        .withColumn(\n",
    "            \"Period\",\n",
    "            F.when(\n",
    "                F.col(\"fp\").isin([\"FY\"]),\n",
    "                F.concat_ws(\n",
    "                    \"\",\n",
    "                    F.col(\"fp\"),\n",
    "                    F.regexp_extract(\n",
    "                        F.year(F.date_trunc(\"year\", F.col(\"fy_end\"))).cast(\n",
    "                            StringType()\n",
    "                        ),\n",
    "                        \"^\\\\d{2}(\\\\d{2})$\",\n",
    "                        1,\n",
    "                    ),\n",
    "                ),\n",
    "            ).otherwise(\n",
    "                F.concat_ws(\n",
    "                    \"\",\n",
    "                    F.reverse(F.col(\"fp\")),\n",
    "                    F.regexp_extract(\n",
    "                        F.year(F.date_trunc(\"year\", F.col(\"fy_end\"))).cast(\n",
    "                            StringType()\n",
    "                        ),\n",
    "                        \"^\\\\d{2}(\\\\d{2})$\",\n",
    "                        1,\n",
    "                    ),\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        .select(\"start\", \"end\", \"fp\", \"Period\", \"val\", \"filed\")\n",
    "    )\n",
    "    max_end_fy = fy_all_q_union_df_fy_rows.selectExpr(\" max(fy_end) as max_end_fy \")\n",
    "    try:\n",
    "        period_val_max_end_fy = (\n",
    "            upto_latest_fy_pc_df.join(\n",
    "                max_end_fy, on=F.col(\"end\") == F.col(\"max_end_fy\"), how=\"inner\"\n",
    "            )\n",
    "            .selectExpr(\"regexp_extract(Period, r'^.*(\\\\d{2,}).*$', 1)\")\n",
    "            .first()[0]\n",
    "        )\n",
    "        period_for_latest_q_rows = str(int(period_val_max_end_fy) + 1)\n",
    "        fy_all_q_union_latest_q_pc_rows = fy_all_q_union_latest_q_rows.withColumn(\n",
    "            \"Period\",\n",
    "            F.concat_ws(\"\", F.reverse(F.col(\"fp\")), F.lit(period_for_latest_q_rows)),\n",
    "        ).select(\"start\", \"end\", \"fp\", \"Period\", \"val\", \"filed\")\n",
    "    except TypeError:\n",
    "        return upto_latest_fy_pc_df\n",
    "    return upto_latest_fy_pc_df.unionByName(fy_all_q_union_latest_q_pc_rows)\n",
    "\n",
    "\n",
    "def get_raw_table_format(fy_all_q_union_df, Ticker):\n",
    "    # raw format\n",
    "    fy_all_q_union_raw_table_df = (\n",
    "        fy_all_q_union_df.withColumn(\"Ticker\", F.lit(f\"{Ticker}\" + \" \" + \"US Equity\"))\n",
    "        .withColumn(\"Period_Startdate\", F.date_format(F.col(\"start\"), \"M/d/y\"))\n",
    "        .withColumn(\"Period_Reportdate\", F.date_format(F.col(\"filed\"), \"M/d/y\"))\n",
    "        .withColumn(\"Period_Enddate\", F.date_format(F.col(\"end\"), \"M/d/y\"))\n",
    "        .withColumn(\"Value\", F.format_number(F.col(\"val\"), \"###,###\"))\n",
    "        .withColumn(\"KPI\", F.lit(\"rev_Topline\"))\n",
    "        .withColumn(\n",
    "            \"Source\",\n",
    "            F.when(\n",
    "                F.col(\"fp\").isin([\"FY\", \"Q4\"]),\n",
    "                F.concat_ws(\" \", F.lit(\"10-K\"), F.col(\"Period\")),\n",
    "            ).otherwise(F.concat_ws(\" \", F.lit(\"10-Q\"), F.col(\"Period\"))),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fy_all_q_union_raw_table_df = fy_all_q_union_raw_table_df.select(\n",
    "        [\n",
    "            \"Ticker\",\n",
    "            \"Period\",\n",
    "            \"Period_Startdate\",\n",
    "            \"Period_Enddate\",\n",
    "            \"Period_Reportdate\",\n",
    "            \"KPI\",\n",
    "            \"Value\",\n",
    "            \"Source\"\n",
    "        ]\n",
    "    ).filter((F.col(\"Period\").rlike(\"Q|F\")) & (F.col(\"val\") > 0))\n",
    "    return fy_all_q_union_raw_table_df\n",
    "\n",
    "\n",
    "def get_not_in_raw_data_lake(fy_all_q_union_df, Ticker):\n",
    "    try:\n",
    "        raw_df = spark.sql(\"\"\"  select * from delta.`/Volumes/revenue_benchmarking/sec_gov_api_data/raw_data_lake` where ticker = f\"{Ticker} US Equity\" \"\"\")\n",
    "    except:\n",
    "        return fy_all_q_union_df\n",
    "    not_in_raw_df = (\n",
    "        F.broadcast(\n",
    "            fy_all_q_union_df.withColumn(\n",
    "                \"period_sub_str\", F.col(\"period\").substr(0, 2)\n",
    "            ).alias(\"a\")\n",
    "        )\n",
    "        .join(raw_df\n",
    "            # .filter(F.col(\"kpi\") == \"rev_Topline\")\n",
    "            # .filter(F.col(\"value\").isNotNull())\n",
    "            .select(\"period\", \"period_startdate\", \"period_enddate\")\n",
    "            .withColumn(\"period_sub_str\", F.col(\"period\").substr(0, 2))\n",
    "            .alias(\"b\"),\n",
    "            on=(F.col(\"a.Period_Startdate\") == F.col(\"b.period_startdate\"))\n",
    "            & (F.col(\"a.Period_Enddate\") == F.col(\"b.period_enddate\"))\n",
    "            & (F.col(\"a.period_sub_str\") == F.col(\"b.period_sub_str\")),\n",
    "            how=\"left_anti\",\n",
    "        )\n",
    "        .drop(\"period_sub_str\")\n",
    "    )\n",
    "    return not_in_raw_df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "helper_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
